{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c40a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import math\n",
    "import time,os\n",
    "\n",
    "from Plot_utils import *\n",
    "from flow_utils import *\n",
    "#from utils import plot_s\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae42c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class planar_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Network for planar flow with linear transform and tanh activation\n",
    "    \"\"\"\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.w = nn.Parameter(torch.randn(1, 2).normal_(0, 0.1))\n",
    "        self.b = nn.Parameter(torch.randn(1).normal_(0, 0.1))\n",
    "        self.u = nn.Parameter(torch.randn(1, 2).normal_(0, 0.1))\n",
    "        \n",
    "        if (torch.mm(self.u, self.w.T)< -1).any():   \n",
    "            self.get_u_hat()\n",
    "\n",
    "\n",
    "        \n",
    "    def get_u_hat(self):\n",
    "        \"\"\"Enforce w^T u >= -1. When using h(.) = tanh(.), this is a sufficient condition \n",
    "        for invertibility of the transformation f(z). See Appendix A.1.\n",
    "        \"\"\"\n",
    "        wtu = torch.mm(self.u, self.w.T)\n",
    "        m_wtu = -1 + torch.log(1 + torch.exp(wtu))\n",
    "        self.u.data = (self.u + (m_wtu - wtu) * self.w / torch.norm(self.w, p=2, dim=1) ** 2)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        z = torch.matmul(x, self.w.T)      \n",
    "        z = torch.add(z, self.b)               \n",
    "        z = nn.tanh(z)                       \n",
    "        z = torch.matmul(z, self.u)           \n",
    "        z = z + x                                \n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a1c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic class for flow functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "    @property    \n",
    "    def base_dist(self):\n",
    "        return Normal(\n",
    "            loc=torch.zeros(2,device=device),\n",
    "            scale=torch.ones(2,device=device), validate_args=False\n",
    "        )\n",
    "      \n",
    "        \n",
    "    def build(self): \n",
    "        \n",
    "        return NotImplemented\n",
    "        \n",
    "    def flow_outputs(self, x):\n",
    "        \n",
    "        log_det = torch.zeros(x.shape[0], device=self.device)\n",
    "        z = x\n",
    "        for bijection in self.flow:\n",
    "            z, ldj = bijection(z)\n",
    "            log_det += ldj\n",
    "            \n",
    "        return z, log_det\n",
    "    \n",
    "    def sample(self, num_samples):\n",
    "        z = self.base_dist.sample((num_samples,))\n",
    "        for bijection in reversed(self.flow):\n",
    "            z = bijection.inverse(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9d47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(function, initial, iteration=100, convergence=torch.Tensor([0.0001, 0.0001]).to(device)):\n",
    "            for i in range(iteration): \n",
    "                previous_data = initial.clone()\n",
    "                value = function(initial)\n",
    "                value.sum().backward()\n",
    "                # update \n",
    "                initial.data -= (value / initial.grad).data\n",
    "                # zero out current gradient to hold new gradients in next iteration \n",
    "                initial.grad.data.zero_() \n",
    "#                 print(\"epoch {}, obtain {}\".format(i, initial))\n",
    "                # Check convergence. \n",
    "                # When difference current epoch result and previous one is less than \n",
    "                # convergence factor, return result.\n",
    "                comp = torch.le(torch.abs(initial - previous_data).data, torch.tensor(convergence))\n",
    "                \n",
    "                if comp.all() == True:\n",
    "                    return initial.data\n",
    "            return initial.data # return our final after iteration\n",
    "\n",
    "class Planar(nn.Module):\n",
    "    \"\"\"\n",
    "    Planar flow as introduced in arXiv: 1505.05770\n",
    "        f(z) = z + u * h(w * z + b)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        z = self.net(x)\n",
    "            \n",
    "        for name, param in self.net.named_parameters():\n",
    "            if name == 'u' : \n",
    "                self.u = param\n",
    "            elif name == 'w' : \n",
    "                self.w = param\n",
    "            elif name == 'b' : \n",
    "                self.b = param\n",
    "        \n",
    "        affine = torch.mm(x, self.w.T) + self.b          \n",
    "        psi = (1 - nn.Tanh()(affine) ** 2) * self.w      \n",
    "        abs_det = (1 + torch.mm(self.u, psi.T)).abs()   \n",
    "        log_det = torch.log(1e-4 + abs_det).squeeze(0)   \n",
    "        \n",
    "        return z, log_det\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        \n",
    "        sol = torch.zeros(torch.Size([450,2])).to(device)\n",
    "        for idx, sample in enumerate(z):\n",
    "            print(str(idx), sample, 'sample')\n",
    "            sample.requires_grad_()\n",
    "            s = newton_method(self.net, sample)\n",
    "            print(s, 's')\n",
    "            sol[idx] = s\n",
    "            \n",
    "        sol = sol.reshape([450,2])    \n",
    "        return sol\n",
    "    \n",
    "class PlanarFlow(Flow):   \n",
    "\n",
    "    def __init__(self, net = planar_net, dim=10):\n",
    "        Flow.__init__(self) \n",
    "        self.net = net\n",
    "        self.dim = dim\n",
    "        self.bijections = []\n",
    "        self.build()\n",
    "        self.flow = nn.ModuleList(self.bijections)  \n",
    "\n",
    "    def build(self): \n",
    "        for i in range(self.dim):\n",
    "            self.bijections += [Planar(self.net)]\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = self.base_dist.sample((num_samples,))\n",
    "        \n",
    "        z = nn.Sequential(reversed(self.flow))\n",
    "            \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deef5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Planar()\n",
      "  (1): Planar()\n",
      "  (2): Planar()\n",
      "  (3): Planar()\n",
      "  (4): Planar()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=planar_net\n",
    "flow_planar = PlanarFlow(net = net, dim= 5).to(device)\n",
    "print(flow_planar.flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4b534f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reversed is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sl/v3s2npss56zf0yrgt28q766m0000gp/T/ipykernel_71685/723651437.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_planar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sl/v3s2npss56zf0yrgt28q766m0000gp/T/ipykernel_71685/924191422.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36madd_module\u001b[0;34m(self, name, module)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             raise TypeError(\"{} is not a Module subclass\".format(\n\u001b[0m\u001b[1;32m    382\u001b[0m                 torch.typename(module)))\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reversed is not a Module subclass"
     ]
    }
   ],
   "source": [
    "z_samples = flow_planar.sample(450)\n",
    "z_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fe03c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
