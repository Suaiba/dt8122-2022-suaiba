{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2f478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import math\n",
    "import time,os\n",
    "\n",
    "from Plot_utils import *\n",
    "from flow_utils import *\n",
    "#from utils import plot_s\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00b1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_dist():\n",
    "    return Normal(\n",
    "        loc=torch.zeros(2, device=device),\n",
    "        scale=torch.ones(2, device=device),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bebe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class planar_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Network for planar flow with linear transform and tanh activation\n",
    "    \"\"\"\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.w = nn.Parameter(torch.randn(1, 2).normal_(0, 0.1))\n",
    "        self.b = nn.Parameter(torch.randn(1).normal_(0, 0.1))\n",
    "        self.u = nn.Parameter(torch.randn(1, 2).normal_(0, 0.1))\n",
    "        \n",
    "        if (torch.mm(self.u, self.w.T)< -1).any():   \n",
    "            self.get_u_hat()\n",
    "\n",
    "\n",
    "        \n",
    "    def get_u_hat(self):\n",
    "        \"\"\"Enforce w^T u >= -1. When using h(.) = tanh(.), this is a sufficient condition \n",
    "        for invertibility of the transformation f(z). See Appendix A.1.\n",
    "        \"\"\"\n",
    "        wtu = torch.mm(self.u, self.w.T)\n",
    "        m_wtu = -1 + torch.log(1 + torch.exp(wtu))\n",
    "        self.u.data = (self.u + (m_wtu - wtu) * self.w / torch.norm(self.w, p=2, dim=1) ** 2)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        z = torch.matmul(x, self.w.T)      \n",
    "        z = torch.add(z, self.b)               \n",
    "        z = nn.tanh(z)                       \n",
    "        z = torch.matmul(z, self.u)           \n",
    "        z = z + x                                \n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6211f9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVP_flow(\n",
      "  (bijections): ModuleList(\n",
      "    (0): Planar()\n",
      "    (1): Planar()\n",
      "    (2): Planar()\n",
      "    (3): Planar()\n",
      "    (4): Planar()\n",
      "    (5): Planar()\n",
      "    (6): Planar()\n",
      "    (7): Planar()\n",
      "    (8): Planar()\n",
      "    (9): Planar()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def newton_method(function, initial, iteration=100, convergence=torch.Tensor([0.0001, 0.0001]).to(device)):\n",
    "            for i in range(iteration): \n",
    "                previous_data = initial.clone()\n",
    "                value = function(initial)\n",
    "                value.sum().backward()\n",
    "                # update \n",
    "                initial.data -= (value / initial.grad).data\n",
    "                # zero out current gradient to hold new gradients in next iteration \n",
    "                initial.grad.data.zero_() \n",
    "#                 print(\"epoch {}, obtain {}\".format(i, initial))\n",
    "                # Check convergence. \n",
    "                # When difference current epoch result and previous one is less than \n",
    "                # convergence factor, return result.\n",
    "                comp = torch.le(torch.abs(initial - previous_data).data, torch.tensor(convergence))\n",
    "                \n",
    "                if comp.all() == True:\n",
    "                    return initial.data\n",
    "            return initial.data # return our final after iteration\n",
    "\n",
    "class Planar(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Planar flow as introduced in arXiv: 1505.05770\n",
    "        f(z) = z + u * h(w * z + b)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, net=planar_net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        # g = f^-1\n",
    "        z = self.net(x)\n",
    "            \n",
    "        for name, param in self.net.named_parameters():\n",
    "            if name == 'u' : \n",
    "                self.u = param\n",
    "            elif name == 'w' : \n",
    "                self.w = param\n",
    "            elif name == 'b' : \n",
    "                self.b = param\n",
    "        \n",
    "        affine = torch.mm(x, self.w.T) + self.b          \n",
    "        psi = (1 - nn.Tanh()(affine) ** 2) * self.w      \n",
    "        abs_det = (1 + torch.mm(self.u, psi.T)).abs()    \n",
    "        log_det = torch.log(1e-4 + abs_det).squeeze(0)   \n",
    "        \n",
    "        return z, log_det\n",
    "\n",
    "    def inverse(self, z):\n",
    "        \n",
    "        sol = torch.zeros(torch.Size([450,2])).to(device)\n",
    "        for idx, sample in enumerate(z):\n",
    "            #print(str(idx), sample, 'sample')\n",
    "            sample.requires_grad_()\n",
    "            s = newton_method(self.net, sample)\n",
    "            #print(s, 's')\n",
    "            sol[idx] = s\n",
    "            \n",
    "        sol = sol.reshape([450,2])    \n",
    "        return sol\n",
    "\n",
    "\n",
    "\n",
    "flow_planar = NVP_flow([Planar(planar_net)]*10)\n",
    "\n",
    "print(flow_planar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28b3853e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sl/v3s2npss56zf0yrgt28q766m0000gp/T/ipykernel_69828/4187172760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_planar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/dt8122-2022-main/flow_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbijection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbijection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sl/v3s2npss56zf0yrgt28q766m0000gp/T/ipykernel_69828/894556025.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#print(str(idx), sample, 'sample')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewton_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;31m#print(s, 's')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sl/v3s2npss56zf0yrgt28q766m0000gp/T/ipykernel_69828/894556025.py\u001b[0m in \u001b[0;36mnewton_method\u001b[0;34m(function, initial, iteration, convergence)\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mprevious_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;31m# update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "z_samples = flow_planar.sample(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0a189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
